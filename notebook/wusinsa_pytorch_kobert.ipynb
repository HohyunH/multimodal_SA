{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6-final"},"colab":{"name":"wusinsa_pytorch_kobert.ipynb","provenance":[{"file_id":"10ijnGjboeqs22dLolQQhd-lwL-81lcvH","timestamp":1627213293944},{"file_id":"https://github.com/SKTBrain/KoBERT/blob/master/scripts/NSMC/naver_review_classifications_pytorch_kobert.ipynb","timestamp":1626959012395}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y0MXAt_hS5L2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636115365844,"user_tz":-540,"elapsed":24526,"user":{"displayName":"Hohyun Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18073395245965959785"}},"outputId":"53a3e38b-1729-46b9-e2bb-891ad4986a52"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"lkn2Uv779D_m"},"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usg8gLPWDaW8"},"source":["!pip install transformers==3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4KivUy79D_o"},"source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"buXhgptD9D_o"},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyyS5IhQ9D_p"},"source":["from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VfBXZLi9D_p"},"source":["from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HQjwLdSZTzP"},"source":["import re\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nJM0zZLE9D_p"},"source":["##GPU 사용 시\n","device = torch.device(\"cuda:0\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOiuMzF6g13T"},"source":["train = pd.read_csv(\"/content/drive/My Drive/crawling_20211104.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOWKg5v8g3Pi"},"source":["df_shuffled=train.iloc[np.random.permutation(train.index)].reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfOdFZzO0U58"},"source":["train = df_shuffled.copy()\n","\n","label = []\n","for s in train['scores']:\n","  if s == \"width: 100%\":\n","    label.append(0)\n","  elif s == \"width: 80%\":\n","    label.append(1)\n","  else:\n","    label.append(2)\n","\n","train['label'] = label\n","\n","train_df = train[:-8000]\n","val_df = train[-8000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLSGbfRrGkfd"},"source":["using_train_data = train_df[['rvs', 'label', 'categories', 'retypes',\n","       'meta_sizes', 'meta_brights', 'meta_colors', 'meta_thicks', ]]\n","      #  'pur_option', 'cus_sex', 'cus_height', 'cus_weight']]\n","\n","using_val_data = val_df[['rvs', 'label', 'categories', 'retypes',\n","       'meta_sizes', 'meta_brights', 'meta_colors', 'meta_thicks', ]]\n","      #  'pur_option', 'cus_sex', 'cus_height', 'cus_weight']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxSky7dsGZfP"},"source":["using_data = train[['rvs', 'label', 'retypes', 'categories', 'meta_sizes', 'meta_brights', 'meta_colors', 'meta_thicks']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTQCu0SGFuCK"},"source":["meta_df = pd.DataFrame()\n","for c in using_data.columns.tolist()[2:]:\n","  dummy_cate = pd.get_dummies(using_data[c])\n","  meta_df = pd.concat([meta_df, dummy_cate], axis=1)\n","\n","train_meta_df = meta_df[:-8000]\n","val_meta_df = meta_df[-8000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TG-egxej9D_q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636115781252,"user_tz":-540,"elapsed":72353,"user":{"displayName":"Hohyun Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18073395245965959785"}},"outputId":"822c07e2-3234-48e5-d95f-40a9b5862a43"},"source":["bertmodel, vocab = get_pytorch_kobert_model()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[██████████████████████████████████████████████████]\n","[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","metadata":{"id":"R-MwXDDR9D_s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636115784587,"user_tz":-540,"elapsed":529,"user":{"displayName":"Hohyun Hwang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18073395245965959785"}},"outputId":"0b784735-fe38-42cd-bc7d-42cf422fc9c3"},"source":["tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model\n"]}]},{"cell_type":"code","metadata":{"id":"69szACaB9D_s"},"source":["class BERTDataset(Dataset):\n","    def __init__(self, df, meta_df, bert_tokenizer, max_len,\n","                 pad, pair, only_ct=True):\n","      \n","        self.only_ct= only_ct\n","        self.df = df\n","        self.meta_df = meta_df\n","\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        def clean_text(sent):\n","            sent_clean=re.sub(\"[^가-힣ㄱ-하-ㅣ]\", \" \", sent)\n","            return sent_clean\n","        \n","        self.sentences = [transform([clean_text(str(i[0]))]) for i in list(df.iloc[:, 0])]\n","\n","    def __getitem__(self, idx):\n","\n","        label = torch.tensor(self.df.iloc[idx, 1])\n","\n","        if self.only_ct:\n","            meta = self.meta_df.iloc[idx, :]\n","        else:\n","            meta = self.meta_df.iloc[idx, 3:9]\n","        meta = torch.tensor(meta).float()\n","\n","        return (self.sentences[idx] + (label, ), meta)\n","\n","    def __len__(self):\n","        return (len(self.sentences))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABqydQaY9D_t"},"source":["## Setting parameters\n","max_len = 64\n","batch_size = 2\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IzuSRhOs9D_t"},"source":["data_trains = BERTDataset(using_train_data, train_meta_df, tok, max_len, True, False)\n","data_tests = BERTDataset(using_val_data, val_meta_df, tok, max_len, True, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ahitq839D_t"},"source":["train_dataloader = torch.utils.data.DataLoader(data_trains, batch_size=batch_size, num_workers=2)\n","test_dataloader = torch.utils.data.DataLoader(data_tests, batch_size=batch_size, num_workers=2, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRld_Tly9D_u"},"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 meta_input_dim = 21,\n","                 meta_hidden_dim = 64,\n","                 hidden_size = 768,\n","                 num_classes=3,\n","                 dr_rate=None,\n","                 params=None,\n","                 use_m=True\n","                 ):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","        self.use_m = use_m\n","        \n","        if self.use_m:\n","          self.classifier = nn.Sequential(\n","              nn.Linear(hidden_size + meta_input_dim, hidden_size), #hidden*2\n","              nn.Linear(hidden_size, num_classes)\n","          )\n","\n","        else:\n","          self.classifier = nn.Sequential(\n","              nn.Linear(hidden_size, hidden_size),\n","              nn.Linear(hidden_size, num_classes)\n","          )\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","            \n","        self.meta_feature = nn.Sequential(\n","            nn.Linear(meta_input_dim, meta_hidden_dim),\n","            nn.Linear(meta_hidden_dim, meta_input_dim)\n","        )\n","\n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids, meta_onehot):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        if self.use_m :\n","          meta_feature = self.meta_feature(meta_onehot)\n","          out = torch.cat([out, meta_feature], dim=1)\n","        return self.classifier(out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hb3FGXls9D_u"},"source":["model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6TuTCZg9D_u"},"source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbhS_xN89D_u"},"source":["optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3Bo8qDM9D_u"},"source":["t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cf_7dTXL9D_v"},"source":["scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9CHcBRm9D_v"},"source":["def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKvndre09D_v"},"source":["for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    model.train()\n","    for batch_id, ((token_ids, valid_length, segment_ids, label), meta) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        meta = meta.to(device)\n","        out = model(token_ids, valid_length, segment_ids, meta)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","            torch.save(model.state_dict(), \"./drive/MyDrive/dacon/bert_model.pt\")\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    \n","    model.eval()\n","    for batch_id, ((token_ids, valid_length, segment_ids, label), meta) in enumerate(tqdm_notebook(test_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        meta = meta.to(device)\n","        out = model(token_ids, valid_length, segment_ids, meta)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSMgvRqqwo5X"},"source":[""],"execution_count":null,"outputs":[]}]}